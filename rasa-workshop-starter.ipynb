{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building conversational AI with the Rasa stack\n",
    "![alt text](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTaX3LNhGcAe1HnPZSuWS0oH6af0LJHXcH7If1sQgLCFAT1chNGFg)\n",
    "\n",
    "\n",
    "This notebook is a basis for my workshop at PyData 2018 Berlin. If you have any questions or would like to learn more about anything included in this notebook, please let me know or get in touch by juste@rasa.com.\n",
    "\n",
    "In this workshop we are going to build a chatbot capable of checking in on people's mood and take the necessary actions to cheer them up. \n",
    "\n",
    "\n",
    "The tutorial consists of three parts:\n",
    "\n",
    "\n",
    "*   Part 0: Installation and setup\n",
    "*   Part 1: Teaching the chatbot to understand user inputs using Rasa NLU model\n",
    "*   Part 2: Teaching the chatbot to handle multi-turn conversations using dialogue management model.\n",
    "*   Part 3: Resources and tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Installation\n",
    "\n",
    "### Let's start with jupyter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging, io, json, warnings\n",
    "logging.basicConfig(level=\"INFO\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def pprint(o):\n",
    "    # small helper to make dict dumps a bit prettier\n",
    "    print(json.dumps(o, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of Rasa\n",
    "Let's start with the installation of Rasa NLU, Rasa Core and a spacy language model. If you have already installed, you can skip this step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "python = sys.executable\n",
    "\n",
    "# In your environment run:\n",
    "!{python} -m pip install -U rasa_core==0.9.6 rasa_nlu[spacy];\n",
    "\n",
    "# as well as install a language model:\n",
    "!{python} -m spacy download en_core_web_md\n",
    "!{python} -m spacy link en_core_web_md en --force;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the installation - we should have rasa_nlu: 0.12.3 and rasa_core: 0.9.6 installed, and spacy model should be available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasa_nlu\n",
    "import rasa_core\n",
    "import spacy\n",
    "\n",
    "print(\"rasa_nlu: {} rasa_core: {}\".format(rasa_nlu.__version__, rasa_core.__version__))\n",
    "print(\"Loading spaCy language model...\")\n",
    "print(spacy.load(\"en\")(\"Hello world!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some additional Tools needed\n",
    "To do some of the visualizations you will also need graphviz. If you don't have graphviz installed, and this doesn't work: don't worry. I'll show you the graph and besides that visualization everything else will work.\n",
    "\n",
    "Try installing with anyone of these (or adapt to your operating system):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get -qq install -y graphviz libgraphviz-dev pkg-config;\n",
    "!brew install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and another python package and we are ready to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{python} -m pip install pygraphviz;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Natural Language Understanding\n",
    "\n",
    "At first, let's teach our chatbot how to understand user inputs. To do that, we are going to build a Rasa NLU model. Here is some data to get started: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversation_1:**   \n",
    "U: Hello  \n",
    "B: Hello, how are you doing?  \n",
    "U: I am doing great!  \n",
    "B: Great. Carry on!  \n",
    "    \n",
    "**Conversation_2:**  \n",
    "U: Hey  \n",
    "B: Hello, how are you doing?  \n",
    "U: I am very sad  \n",
    "B: To cheer you up, I can show you a cute picture of a cat, a dog or a bird. Choose one :)  \n",
    "U: A kitten  \n",
    "B: Here is something to cheer you up. Did that help?  \n",
    "U: Yes  \n",
    "B: Goodbye  \n",
    "  \n",
    "**Conversation_3:**    \n",
    "U: Heya  \n",
    "B: Hello, how are you doing?  \n",
    "U: Not so good and the only thing that could help me feel better is a picture of a puppy  \n",
    "B: Here is something to cheer you up. Did that help?  \n",
    "U: No  \n",
    "B: Goodbye  \n",
    "U: Bye  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the training data for language understanding model\n",
    "\n",
    "\n",
    "Lets create some training data here, grouping user messages by their `intents`. The intent describes what the messages *mean*. Another important part of training data are `entities` - pieces of information which help a chatbot understand what specifically a user is asking about. Entities are labeled using the markdown link syntex: `[entity value](entity_type)` [More information about the data format](https://nlu.rasa.com/dataformat.html#markdown-format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_md = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the NLU model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the training data is ready, we can define our NLU model. We can do that by constructing the processing pipeline which defines how structured data is extracted from unstructured user inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"\"\"\n",
    "language: \"en\"\n",
    "\n",
    "pipeline:\n",
    "- name: \"nlp_spacy\"                   # loads the spacy language model\n",
    "- name: \"tokenizer_spacy\"             # splits the sentence into tokens\n",
    "- name: \"intent_featurizer_spacy\"     # transform the sentence into a vector representation\n",
    "- name: \"intent_classifier_sklearn\"   # uses the vector representation to classify using SVM\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "%store config > config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Rasa NLU Model\n",
    "\n",
    "We're going to train a model to recognise user inputs, so that when you send a message like \"hello\" to your bot, it will recognise this as a `\"greet\"` intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer\n",
    "from rasa_nlu import config\n",
    "\n",
    "# loading the nlu training samples\n",
    "training_data = load_data(\"nlu.md\")\n",
    "\n",
    "# trainer to educate our pipeline\n",
    "trainer = Trainer(config.load(\"config.yml\"))\n",
    "\n",
    "# train the model!\n",
    "interpreter = trainer.train(training_data)\n",
    "\n",
    "# store it for future use\n",
    "model_directory = trainer.persist(\"./models/nlu\", fixed_model_name=\"current\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using & evaluating the NLU model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the model is performing on some of the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(interpreter.parse(\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of evaluating it by hand, the model can also be evaluated on a test data set (though for simplicity we are going to use the same for test and train):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.evaluate import run_evaluation\n",
    "\n",
    "run_evaluation(\"nlu.md\", model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Handling the dialogue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have taught our chatbot how to understand user inputs. Now, it's time to teach our chatbot how to make responses by training a dialogue management model using Rasa Core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Stories\n",
    "\n",
    "The training data for dialogue management models is called `stories`. A story is an actual conversation where user inputs are expressed as intents as well as corresponding entities, and chatbot responses are expressed as actions.\n",
    "\n",
    "\n",
    "Let's take a look into the format of the stories in more detail:\n",
    "\n",
    "A story starts with `##` and you can give it a name. \n",
    "Lines that start with `*` are messages sent by the user. Although you don't write the *actual* message, but rather the intent (and the entities) that represent what the user *means*. \n",
    "Lines that start with `-` are *actions* taken by your bot. In this case all of our actions are just messages sent back to the user, like `utter_greet`, but in general an action can do anything, including calling an API and interacting with the outside world. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stories_md = \"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "%store stories_md > stories.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a Domain\n",
    "\n",
    "The domain specifies the universe that the bot operates in. In chatbot's world this universe consists of intents and entities as well as the actions which appear in training stories. The domain can also contain the templates for the answers a chabot should use to respond to the user and slots which will help the chatbot to keep track of the context. Let's look into the domain of our bot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_yml = \"\"\"\n",
    "intents:\n",
    "- greet\n",
    "- goodbye\n",
    "- mood_affirm\n",
    "- mood_deny\n",
    "- mood_great\n",
    "- mood_unhappy\n",
    "- inform\n",
    "\n",
    "    \n",
    "entities:\n",
    "- group\n",
    "\n",
    "actions:\n",
    "- utter_greet\n",
    "- utter_did_that_help\n",
    "- utter_happy\n",
    "- utter_goodbye\n",
    "- utter_unclear\n",
    "- utter_ask_picture\n",
    "\n",
    "\n",
    "templates:\n",
    "  utter_greet:\n",
    "  - text: \"Hey! How are you?\"\n",
    "\n",
    "  utter_did_that_help:\n",
    "  - text: \"Did that help you?\"\n",
    "\n",
    "  utter_unclear:\n",
    "  - text: \"I am not sure what you are aiming for.\"\n",
    "  \n",
    "  utter_happy:\n",
    "  - text: \"Great carry on!\"\n",
    "\n",
    "  utter_goodbye:\n",
    "  - text: \"Bye\"\n",
    "  \n",
    "  utter_ask_picture:\n",
    "  - text: \"To cheer you up, I can show you a cute picture of a dog, a cat or a bird. Which one do you choose?\"\n",
    "\"\"\"\n",
    "\n",
    "%store domain_yml > domain.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Custom Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The responses of the chatbot can be more than just simple text responses - we can call an API to retrieve some data which can later be used to create a response to user input. Let's create a custom action for our bot which, when predicted, will make an API and retrieve a picture of a dog, a cat or a bird, depending on which was specified by the user. The bot will know which type of picture should be received by retrieving the value of the slot `group`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.actions import Action\n",
    "from rasa_core.events import SlotSet\n",
    "from IPython.display import Image\n",
    "\n",
    "import requests\n",
    "\n",
    "class ApiAction(Action):\n",
    "    def name(self):\n",
    "        return \"action_retrieve_image\"\n",
    "\n",
    "    def run(self, dispatcher, tracker, domain):\n",
    "        \n",
    "\n",
    "        group = \n",
    "        r = \n",
    "        \n",
    "        response = r.content.decode()\n",
    "        response = response.replace('[\"',\"\")\n",
    "        response = response.replace('\"]',\"\")\n",
    "        \n",
    "        dispatcher.utter_message(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pro Tip: Visualising the Training Data\n",
    "\n",
    "You can visualise the stories to get a sense of how the conversations go. This is usually a good way to see if there are any stories which don't make sense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "agent = Agent('domain.yml')\n",
    "agent.visualize(\"stories.md\", \"story_graph.png\", max_history=2)\n",
    "Image(filename=\"story_graph.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training your Dialogue Model\n",
    "\n",
    "Now we are good to train the dialogue management model. We can specify what policies should be used to train it - in this case, the model is a neural network implemented in Keras which learns to predict which action to take next. We can also tweak the parameters of what percentage of training examples should be used for validation and how many epochs should be used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.policies import FallbackPolicy, KerasPolicy, MemoizationPolicy\n",
    "from rasa_core.agent import Agent\n",
    "\n",
    "# this will catch predictions the model isn't very certain about\n",
    "# there is a threshold for the NLU predictions as well as the action predictions\n",
    "\n",
    "\n",
    "agent = Agent('domain.yml', policies=[MemoizationPolicy(), KerasPolicy()])\n",
    "\n",
    "# loading our neatly defined training dialogues\n",
    "training_data = agent.load_data('stories.md')\n",
    "\n",
    "agent.train(\n",
    "    training_data,\n",
    "    validation_split=0.0,\n",
    "    epochs=200\n",
    ")\n",
    "\n",
    "agent.persist('models/dialogue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting up the bot (with NLU)\n",
    "\n",
    "Now it's time for the fun part - starting the agent and chatting with it. We are going to start the `Agent` by loading our just trained dialogue model and using the previously trained nlu model as an interpreter for incoming user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.agent import Agent\n",
    "agent = Agent.load('models/dialogue', interpreter=model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talking to the Bot (with NLU)\n",
    "\n",
    "Let's have a chat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Your bot is ready to talk! Type your messages here or send 'stop'\")\n",
    "while True:\n",
    "    a = input()\n",
    "    if a == 'stop':\n",
    "        break\n",
    "    responses = agent.handle_message(a)\n",
    "    for response in responses:\n",
    "        print(response[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the dialogue model\n",
    "As with the NLU model, instead of just subjectively testing the model, we can also evaluate the model on a dataset. You'll be using the training data set again, but usually you'd use a test data set separate from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_core.evaluate import run_story_evaluation\n",
    "\n",
    "run_story_evaluation(\"stories.md\", \"models/dialogue\", \n",
    "                     nlu_model_path=None, \n",
    "                     max_stories=None, \n",
    "                     out_file_plot=\"story_eval.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive learning\n",
    "Unfortunately, this doesn't work in Jupyter yet. Hence, we going to do this on the command line. To start the interactive training session open your command line and run `train_online.py` script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources and tips\n",
    "\n",
    "- Rasa NLU [documentation](https://nlu.rasa.com/)\n",
    "- Rasa Core [documentation](https://core.rasa.com/)\n",
    "- Rasa Community on [Gitter](https://gitter.im/RasaHQ/home)\n",
    "- Rasa [Blog](https://blog.rasa.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
